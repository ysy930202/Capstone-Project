{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\yoyo0\\\\Previous project records\\\\STAT656',\n",
       " 'C:\\\\Users\\\\yoyo0\\\\Anaconda3\\\\python37.zip',\n",
       " 'C:\\\\Users\\\\yoyo0\\\\Anaconda3\\\\DLLs',\n",
       " 'C:\\\\Users\\\\yoyo0\\\\Anaconda3\\\\lib',\n",
       " 'C:\\\\Users\\\\yoyo0\\\\Anaconda3',\n",
       " '',\n",
       " 'C:\\\\Users\\\\yoyo0\\\\AppData\\\\Roaming\\\\Python\\\\Python37\\\\site-packages',\n",
       " 'C:\\\\Users\\\\yoyo0\\\\Anaconda3\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\yoyo0\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\yoyo0\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\yoyo0\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\Users\\\\yoyo0\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\yoyo0\\\\.ipython',\n",
       " 'C:/yoyo/course/3rd/656/hom/week5',\n",
       " 'C:/Users/yoyo0/Downloads/graphviz-2.38/release/bin']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "#sys.path\n",
    "\n",
    "sys.path.append(\"C:/yoyo/course/3rd/656/hom/week5\")\n",
    "sys.path.append(\"C:/Users/yoyo0/Downloads/graphviz-2.38/release/bin\")\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Class_tree import DecisionTree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from pydotplus import graph_from_dot_data\n",
    "import graphviz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'C:/yoyo/course/3rd/656/hom/midterm/'\n",
    "df = pd.read_excel(file_path+\"CreditCard_Defaults.xlsx\")\n",
    "n_obs = df.shape[0]\n",
    "n_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_interval = 26\n",
    "n_binary   = 2\n",
    "n_nominal  = 3\n",
    "n_cat = n_binary+n_nominal\n",
    "\n",
    "attribute_map = {\n",
    "    'Default':[1,(1,0),[0,0]],\n",
    "    'Gender':[1,(1,2),[0,0]],\n",
    "    'Education':[2,(0,1,2,3,4,5,6),[0,0]],\n",
    "    'Marital_Status':[2,(0,1,2,3),[0,0]],\n",
    "    'card_class':[2,(1,2,3),[0,0]],\n",
    "    'Age':[0,(20,80),[0,0]],\n",
    "    'Credit_Limit':[0,(100,80000),[0,0]],\n",
    "    'Jun_Status':[0,(-2,8),[0,0]],\n",
    "    'May_Status':[0,(-2,8),[0,0]],\n",
    "    'Apr_Status':[0,(-2,8),[0,0]],\n",
    "    'Mar_Status':[0,(-2,8),[0,0]],\n",
    "    'Feb_Status':[0,(-2,8),[0,0]],\n",
    "    'Jan_Status':[0,(-2,8),[0,0]],\n",
    "    'Jun_Bill':[0,(-12000,32000),[0,0]],\n",
    "    'May_Bill':[0,(-12000,32000),[0,0]],\n",
    "    'Apr_Bill':[0,(-12000,32000),[0,0]],\n",
    "    'Mar_Bill':[0,(-12000,32000),[0,0]],\n",
    "    'Feb_Bill':[0,(-12000,32000),[0,0]],\n",
    "    'Jan_Bill':[0,(-12000,32000),[0,0]],\n",
    "    'Jun_Payment':[0,(0,60000),[0,0]],\n",
    "    'May_Payment':[0,(0,60000),[0,0]],\n",
    "    'Apr_Payment':[0,(0,60000),[0,0]],\n",
    "    'Mar_Payment':[0,(0,60000),[0,0]],\n",
    "    'Feb_Payment':[0,(0,60000),[0,0]],\n",
    "    'Jan_Payment':[0,(0,60000),[0,0]],\n",
    "    'Jun_PayPercent':[0,(0,1),[0,0]],\n",
    "    'May_PayPercent':[0,(0,1),[0,0]],\n",
    "    'Apr_PayPercent':[0,(0,1),[0,0]],\n",
    "    'Mar_PayPercent':[0,(0,1),[0,0]],\n",
    "    'Feb_PayPercent':[0,(0,1),[0,0]],\n",
    "    'Jan_PayPercent':[0,(0,1),[0,0]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of missing values and outliers by attribute:\n",
      "Default:\t0 missing  0 outlier(s)\n",
      "Gender:\t3083 missing  0 outlier(s)\n",
      "Education:\t4521 missing  0 outlier(s)\n",
      "Marital_Status:\t0 missing  0 outlier(s)\n",
      "card_class:\t0 missing  0 outlier(s)\n",
      "Age:\t5999 missing  0 outlier(s)\n",
      "Credit_Limit:\t0 missing  0 outlier(s)\n",
      "Jun_Status:\t0 missing  0 outlier(s)\n",
      "May_Status:\t0 missing  0 outlier(s)\n",
      "Apr_Status:\t0 missing  0 outlier(s)\n",
      "Mar_Status:\t0 missing  0 outlier(s)\n",
      "Feb_Status:\t0 missing  0 outlier(s)\n",
      "Jan_Status:\t0 missing  0 outlier(s)\n",
      "Jun_Bill:\t0 missing  1 outlier(s)\n",
      "May_Bill:\t0 missing  1 outlier(s)\n",
      "Apr_Bill:\t0 missing  1 outlier(s)\n",
      "Mar_Bill:\t0 missing  0 outlier(s)\n",
      "Feb_Bill:\t0 missing  0 outlier(s)\n",
      "Jan_Bill:\t0 missing  1 outlier(s)\n",
      "Jun_Payment:\t0 missing  0 outlier(s)\n",
      "May_Payment:\t0 missing  0 outlier(s)\n",
      "Apr_Payment:\t0 missing  0 outlier(s)\n",
      "Mar_Payment:\t0 missing  0 outlier(s)\n",
      "Feb_Payment:\t0 missing  0 outlier(s)\n",
      "Jan_Payment:\t0 missing  0 outlier(s)\n",
      "Jun_PayPercent:\t0 missing  0 outlier(s)\n",
      "May_PayPercent:\t0 missing  0 outlier(s)\n",
      "Apr_PayPercent:\t0 missing  0 outlier(s)\n",
      "Mar_PayPercent:\t0 missing  0 outlier(s)\n",
      "Feb_PayPercent:\t0 missing  0 outlier(s)\n",
      "Jan_PayPercent:\t0 missing  0 outlier(s)\n"
     ]
    }
   ],
   "source": [
    "initial_missing = df.isnull().sum()\n",
    "for k,v in attribute_map.items():\n",
    "    v[2][0] = initial_missing[k]\n",
    "nan_map = df.isnull()\n",
    "\n",
    "for i in range(n_obs):\n",
    "    # Check for outliers in interval attributes\n",
    "    if i ==0:\n",
    "        i = i+1\n",
    "    for k, v in attribute_map.items():\n",
    "        if nan_map.loc[i,k]==True:\n",
    "            continue\n",
    "        if v[0]==0: # Interval Attribute\n",
    "            l_limit = v[1][0]\n",
    "            u_limit = v[1][1]\n",
    "            if df.loc[i,k]>u_limit or df.loc[i,k]<l_limit:\n",
    "                v[2][1] += 1\n",
    "                df.loc[i,k] = None\n",
    "        else: # Categorical Attribute\n",
    "            in_cat = False\n",
    "            for cat in v[1]:\n",
    "                if df.loc[i,k]==cat:\n",
    "                    in_cat=True\n",
    "            if in_cat==False:\n",
    "                df.loc[i,k] = None\n",
    "                v[2][1] += 1\n",
    "                \n",
    "print(\"\\nNumber of missing values and outliers by attribute:\")\n",
    "feature_names = np.array(df.columns.values)\n",
    "for k,v in attribute_map.items():\n",
    "    print(k+\":\\t%i missing\" %v[2][0]+ \"  %i outlier(s)\" %v[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_attributes = []\n",
    "nominal_attributes  = []\n",
    "binary_attributes = []\n",
    "onehot_attributes   = []\n",
    "for k,v in attribute_map.items():\n",
    "    if v[0]==0:\n",
    "        interval_attributes.append(k)\n",
    "    else:\n",
    "        if v[0]==1:\n",
    "            binary_attributes.append(k)\n",
    "        else:\n",
    "            nominal_attributes.append(k)\n",
    "            for i in range(len(v[1])):\n",
    "                str = k+(\"%i\" %i)\n",
    "                onehot_attributes.append(str)\n",
    "            \n",
    "n_interval = len(interval_attributes)\n",
    "n_nominal  = len(nominal_attributes)\n",
    "n_binary = len(binary_attributes)\n",
    "n_onehot   = len(onehot_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer</th>\n",
       "      <th>Default</th>\n",
       "      <th>card_class</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Age</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Jun_Status</th>\n",
       "      <th>May_Status</th>\n",
       "      <th>...</th>\n",
       "      <th>Apr_Payment</th>\n",
       "      <th>Mar_Payment</th>\n",
       "      <th>Feb_Payment</th>\n",
       "      <th>Jan_Payment</th>\n",
       "      <th>Jun_PayPercent</th>\n",
       "      <th>May_PayPercent</th>\n",
       "      <th>Apr_PayPercent</th>\n",
       "      <th>Mar_PayPercent</th>\n",
       "      <th>Feb_PayPercent</th>\n",
       "      <th>Jan_PayPercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>700</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2221</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4100</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>34.20</td>\n",
       "      <td>34.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>68.40</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5797</td>\n",
       "      <td>0.3729</td>\n",
       "      <td>0.3056</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.20</td>\n",
       "      <td>34.20</td>\n",
       "      <td>34.20</td>\n",
       "      <td>171.00</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.1069</td>\n",
       "      <td>0.0738</td>\n",
       "      <td>0.0698</td>\n",
       "      <td>0.0669</td>\n",
       "      <td>0.3216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.04</td>\n",
       "      <td>37.62</td>\n",
       "      <td>36.56</td>\n",
       "      <td>34.20</td>\n",
       "      <td>0.0426</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1700</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>342.00</td>\n",
       "      <td>307.80</td>\n",
       "      <td>23.56</td>\n",
       "      <td>23.22</td>\n",
       "      <td>0.2321</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2791</td>\n",
       "      <td>0.4298</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.0355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer  Default  card_class  Gender  Education  Marital_Status   Age  \\\n",
       "0         1        1           1     2.0        2.0               1  24.0   \n",
       "1         2        0           2     2.0        2.0               2  26.0   \n",
       "2         3        0           2     2.0        2.0               2  34.0   \n",
       "3         4        0           1     2.0        2.0               1  37.0   \n",
       "4         5        0           1     1.0        2.0               1  57.0   \n",
       "\n",
       "   Credit_Limit  Jun_Status  May_Status  ...  Apr_Payment  Mar_Payment  \\\n",
       "0           700           2           2  ...         0.00         0.00   \n",
       "1          4100          -1           2  ...        34.20        34.20   \n",
       "2          3100           0           0  ...        34.20        34.20   \n",
       "3          1700           0           0  ...        41.04        37.62   \n",
       "4          1700          -1           0  ...       342.00       307.80   \n",
       "\n",
       "   Feb_Payment  Jan_Payment  Jun_PayPercent  May_PayPercent  Apr_PayPercent  \\\n",
       "0         0.00         0.00          0.0000          0.2221          0.0000   \n",
       "1         0.00        68.40          0.0000          0.5797          0.3729   \n",
       "2        34.20       171.00          0.0519          0.1069          0.0738   \n",
       "3        36.56        34.20          0.0426          0.0419          0.0243   \n",
       "4        23.56        23.22          0.2321          1.0000          0.2791   \n",
       "\n",
       "   Mar_PayPercent  Feb_PayPercent  Jan_PayPercent  \n",
       "0          1.0000          1.0000          1.0000  \n",
       "1          0.3056          0.0000          0.6133  \n",
       "2          0.0698          0.0669          0.3216  \n",
       "3          0.0388          0.0369          0.0338  \n",
       "4          0.4298          0.0360          0.0355  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "    Customer  Default  card_class  Gender  Education  Marital_Status   Age  \\\n",
      "0         1        1           1     2.0        2.0               1  24.0   \n",
      "1         2        0           2     2.0        2.0               2  26.0   \n",
      "2         3        0           2     2.0        2.0               2  34.0   \n",
      "3         4        0           1     2.0        2.0               1  37.0   \n",
      "4         5        0           1     1.0        2.0               1  57.0   \n",
      "\n",
      "   Credit_Limit  Jun_Status  May_Status  ...  Apr_Payment  Mar_Payment  \\\n",
      "0           700           2           2  ...         0.00         0.00   \n",
      "1          4100          -1           2  ...        34.20        34.20   \n",
      "2          3100           0           0  ...        34.20        34.20   \n",
      "3          1700           0           0  ...        41.04        37.62   \n",
      "4          1700          -1           0  ...       342.00       307.80   \n",
      "\n",
      "   Feb_Payment  Jan_Payment  Jun_PayPercent  May_PayPercent  Apr_PayPercent  \\\n",
      "0         0.00         0.00          0.0000          0.2221          0.0000   \n",
      "1         0.00        68.40          0.0000          0.5797          0.3729   \n",
      "2        34.20       171.00          0.0519          0.1069          0.0738   \n",
      "3        36.56        34.20          0.0426          0.0419          0.0243   \n",
      "4        23.56        23.22          0.2321          1.0000          0.2791   \n",
      "\n",
      "   Mar_PayPercent  Feb_PayPercent  Jan_PayPercent  \n",
      "0          1.0000          1.0000          1.0000  \n",
      "1          0.3056          0.0000          0.6133  \n",
      "2          0.0698          0.0669          0.3216  \n",
      "3          0.0388          0.0369          0.0338  \n",
      "4          0.4298          0.0360          0.0355  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoyo0\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\yoyo0\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original DataFrame:\\n\", df[0:5])\n",
    "# Put the interval data from the dataframe into a numpy array\n",
    "interval_data = df.as_matrix(columns=interval_attributes)\n",
    "# Create the Imputer for the Interval Data\n",
    "interval_imputer = preprocessing.Imputer(strategy='mean')\n",
    "# Impute the missing values in the Interval data\n",
    "imputed_interval_data = interval_imputer.fit_transform(interval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoyo0\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "C:\\Users\\yoyo0\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\yoyo0\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Put the nominal and binary data from the dataframe into a numpy array\n",
    "nominal_data = df.as_matrix(columns=nominal_attributes)\n",
    "binary_data  = df.as_matrix(columns=binary_attributes)\n",
    "# Create Imputer for Categorical Data\n",
    "cat_imputer = preprocessing.Imputer(strategy='most_frequent')\n",
    "# Impute the missing values in the Categorical Data\n",
    "imputed_nominal_data = cat_imputer.fit_transform(nominal_data)\n",
    "imputed_binary_data  = cat_imputer.fit_transform(binary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def categorical_summarized(dataframe, x=None, y=None, hue=None, palette='Set1', verbose=True):\n",
    "    '''\n",
    "    Helper function that gives a quick summary of a given column of categorical data\n",
    "    Arguments\n",
    "    =========\n",
    "    dataframe: pandas dataframe\n",
    "    x: str. horizontal axis to plot the labels of categorical data, y would be the count\n",
    "    y: str. vertical axis to plot the labels of categorical data, x would be the count\n",
    "    hue: str. if you want to compare it another variable (usually the target variable)\n",
    "    palette: array-like. Colour of the plot\n",
    "    Returns\n",
    "    =======\n",
    "    Quick Stats of the data and also the count plot\n",
    "    '''\n",
    "    if x == None:\n",
    "        column_interested = y\n",
    "    else:\n",
    "        column_interested = x\n",
    "    series = dataframe[column_interested]\n",
    "    print(series.describe())\n",
    "    print('mode: ', series.mode())\n",
    "    if verbose:\n",
    "        print('='*80)\n",
    "        print(series.value_counts())\n",
    "\n",
    "    sns.countplot(x=x, y=y, hue=hue, data=dataframe, palette=palette)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    30000.000000\n",
      "mean         0.161800\n",
      "std          0.368273\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: Default, dtype: float64\n",
      "mode:  0    0\n",
      "dtype: int64\n",
      "================================================================================\n",
      "0    25146\n",
      "1     4854\n",
      "Name: Default, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Target Variable: Survival\n",
    "c_palette = ['tab:blue', 'tab:orange']\n",
    "categorical_summarized(df, y = 'Default', palette=c_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    26917.000000\n",
      "mean         1.604042\n",
      "std          0.489065\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          2.000000\n",
      "max          2.000000\n",
      "Name: Gender, dtype: float64\n",
      "mode:  0    2.0\n",
      "dtype: float64\n",
      "================================================================================\n",
      "2.0    16259\n",
      "1.0    10658\n",
      "Name: Gender, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature Variable: Gender\n",
    "categorical_summarized(df, y = 'Gender', hue='Default', palette=c_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoding Interval Data by Scaling\n",
    "scaler = preprocessing.StandardScaler() # Create an instance of StandardScaler()\n",
    "scaler.fit(imputed_interval_data)\n",
    "scaled_interval_data = scaler.transform(imputed_interval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an instance of the OneHotEncoder & Selecting Attributes\n",
    "onehot = preprocessing.OneHotEncoder()\n",
    "hot_array = onehot.fit_transform(imputed_nominal_data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imputed DataFrame:\n",
      "           Age  Credit_Limit  Jun_Status  May_Status  Apr_Status  Mar_Status  \\\n",
      "0   24.000000         700.0         2.0         2.0        -1.0        -1.0   \n",
      "1   26.000000        4100.0        -1.0         2.0         0.0         0.0   \n",
      "2   34.000000        3100.0         0.0         0.0         0.0         0.0   \n",
      "3   37.000000        1700.0         0.0         0.0         0.0         0.0   \n",
      "4   57.000000        1700.0        -1.0         0.0        -1.0         0.0   \n",
      "5   37.000000        1700.0         0.0         0.0         0.0         0.0   \n",
      "6   29.000000       17100.0         0.0         0.0         0.0         0.0   \n",
      "7   23.000000        3400.0         0.0        -1.0        -1.0         0.0   \n",
      "8   28.000000        4800.0         0.0         0.0         2.0         0.0   \n",
      "9   35.000000         700.0        -2.0        -2.0        -2.0        -2.0   \n",
      "10  35.493813        6800.0         0.0         0.0         2.0         0.0   \n",
      "11  35.493813        8900.0        -1.0        -1.0        -1.0        -1.0   \n",
      "12  41.000000       21500.0        -1.0         0.0        -1.0        -1.0   \n",
      "13  30.000000        2400.0         1.0         2.0         2.0         0.0   \n",
      "14  29.000000        8600.0         0.0         0.0         0.0         0.0   \n",
      "\n",
      "    Feb_Status  Jan_Status  Jun_Bill  May_Bill   ...    May_PayPercent  \\\n",
      "0         -2.0        -2.0    133.82    106.09   ...            0.2221   \n",
      "1          0.0         2.0     91.72     59.00   ...            0.5797   \n",
      "2          0.0         0.0    999.97    479.72   ...            0.1069   \n",
      "3          0.0         0.0   1607.06   1649.57   ...            0.0419   \n",
      "4          0.0         0.0    294.70    193.91   ...            1.0000   \n",
      "5          0.0         0.0   2202.48   1951.76   ...            0.0318   \n",
      "6          0.0         0.0  12584.40  14091.19   ...            0.0971   \n",
      "7          0.0        -1.0    406.16     13.00   ...            1.0000   \n",
      "8          0.0         0.0    385.95    482.08   ...            0.0000   \n",
      "9         -1.0        -1.0      0.00      0.00   ...            1.0000   \n",
      "10         0.0        -1.0    378.70    334.72   ...            0.0012   \n",
      "11        -1.0         2.0    419.33    741.11   ...            0.4599   \n",
      "12        -1.0        -1.0    415.09    222.30   ...            1.0000   \n",
      "13         0.0         2.0   2250.43   2304.02   ...            0.0000   \n",
      "14         0.0         0.0   2424.34   2293.45   ...            0.0447   \n",
      "\n",
      "    Apr_PayPercent  Mar_PayPercent  Feb_PayPercent  Jan_PayPercent  Education  \\\n",
      "0           0.0000          1.0000          1.0000          1.0000        2.0   \n",
      "1           0.3729          0.3056          0.0000          0.6133        2.0   \n",
      "2           0.0738          0.0698          0.0669          0.3216        2.0   \n",
      "3           0.0243          0.0388          0.0369          0.0338        2.0   \n",
      "4           0.2791          0.4298          0.0360          0.0355        2.0   \n",
      "5           0.0114          0.0516          0.0510          0.0400        1.0   \n",
      "6           0.0854          0.0373          0.0285          0.0291        1.0   \n",
      "7           0.0000          1.0000          1.0000          1.0000        2.0   \n",
      "8           0.0357          0.0819          0.0848          0.2689        3.0   \n",
      "9           1.0000          1.0000          0.0863          0.0000        3.0   \n",
      "10          0.0090          0.1194          1.0000          0.0177        2.0   \n",
      "11          0.8612          1.0000          0.0000          0.2663        2.0   \n",
      "12          1.0000          1.0000          0.4415          0.0000        2.0   \n",
      "13          0.0457          0.0449          0.0415          0.0000        2.0   \n",
      "14          0.0472          0.0503          0.0527          0.0540        1.0   \n",
      "\n",
      "    Marital_Status  card_class  Default  Gender  \n",
      "0              1.0         1.0      1.0     2.0  \n",
      "1              2.0         2.0      0.0     2.0  \n",
      "2              2.0         2.0      0.0     2.0  \n",
      "3              1.0         1.0      0.0     2.0  \n",
      "4              1.0         1.0      0.0     1.0  \n",
      "5              2.0         1.0      0.0     1.0  \n",
      "6              2.0         3.0      0.0     1.0  \n",
      "7              2.0         2.0      0.0     2.0  \n",
      "8              1.0         2.0      0.0     2.0  \n",
      "9              2.0         1.0      0.0     1.0  \n",
      "10             2.0         2.0      0.0     2.0  \n",
      "11             2.0         2.0      0.0     2.0  \n",
      "12             2.0         3.0      0.0     2.0  \n",
      "13             2.0         2.0      0.0     1.0  \n",
      "14             2.0         2.0      0.0     1.0  \n",
      "\n",
      "[15 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "data_array= np.hstack((imputed_interval_data,imputed_nominal_data,imputed_binary_data))\n",
    "col = []\n",
    "for i in range(n_interval):\n",
    "    col.append(interval_attributes[i])\n",
    "for i in range(n_nominal):\n",
    "    col.append(nominal_attributes[i])\n",
    "for i in range(n_binary):\n",
    "    col.append(binary_attributes[i])\n",
    "df_imputed = pd.DataFrame(data_array,columns=col)\n",
    "print(\"\\nImputed DataFrame:\\n\", df_imputed[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imputed & Scaled DataFrame:\n",
      "         Age  Credit_Limit  Jun_Status  May_Status  Apr_Status  Mar_Status  \\\n",
      "0 -1.391899     -1.131883    1.794564    1.782348   -0.696663   -0.666599   \n",
      "1 -1.149700     -0.366111   -0.874991    1.782348    0.138865    0.188746   \n",
      "2 -0.180901     -0.591338    0.014861    0.111736    0.138865    0.188746   \n",
      "3  0.182399     -0.906656    0.014861    0.111736    0.138865    0.188746   \n",
      "4  2.604397     -0.906656   -0.874991    0.111736   -0.696663    0.188746   \n",
      "\n",
      "   Feb_Status  Jan_Status  Jun_Bill  May_Bill   ...    Education6  \\\n",
      "0   -1.530046   -1.486041 -0.643742 -0.648829   ...           0.0   \n",
      "1    0.234917    1.992316 -0.660503 -0.668231   ...           0.0   \n",
      "2    0.234917    0.253137 -0.298915 -0.494888   ...           0.0   \n",
      "3    0.234917    0.253137 -0.057224 -0.012891   ...           0.0   \n",
      "4    0.234917    0.253137 -0.579693 -0.612646   ...           0.0   \n",
      "\n",
      "   Marital_Status0  Marital_Status1  Marital_Status2  Marital_Status3  \\\n",
      "0              0.0              1.0              0.0              0.0   \n",
      "1              0.0              0.0              1.0              0.0   \n",
      "2              0.0              0.0              1.0              0.0   \n",
      "3              0.0              1.0              0.0              0.0   \n",
      "4              0.0              1.0              0.0              0.0   \n",
      "\n",
      "   card_class0  card_class1  card_class2  Default  Gender  \n",
      "0          1.0          0.0          0.0      1.0     2.0  \n",
      "1          0.0          1.0          0.0      0.0     2.0  \n",
      "2          0.0          1.0          0.0      0.0     2.0  \n",
      "3          1.0          0.0          0.0      0.0     2.0  \n",
      "4          1.0          0.0          0.0      0.0     1.0  \n",
      "\n",
      "[5 rows x 42 columns]\n",
      "\n",
      "Imputed & Scaled lgr DataFrame:\n",
      "         Age  Credit_Limit  Jun_Status  May_Status  Apr_Status  Mar_Status  \\\n",
      "0 -1.391899     -1.131883    1.794564    1.782348   -0.696663   -0.666599   \n",
      "1 -1.149700     -0.366111   -0.874991    1.782348    0.138865    0.188746   \n",
      "2 -0.180901     -0.591338    0.014861    0.111736    0.138865    0.188746   \n",
      "3  0.182399     -0.906656    0.014861    0.111736    0.138865    0.188746   \n",
      "4  2.604397     -0.906656   -0.874991    0.111736   -0.696663    0.188746   \n",
      "\n",
      "   Feb_Status  Jan_Status  Jun_Bill  May_Bill   ...    Education3  Education4  \\\n",
      "0   -1.530046   -1.486041 -0.643742 -0.648829   ...           0.0         0.0   \n",
      "1    0.234917    1.992316 -0.660503 -0.668231   ...           0.0         0.0   \n",
      "2    0.234917    0.253137 -0.298915 -0.494888   ...           0.0         0.0   \n",
      "3    0.234917    0.253137 -0.057224 -0.012891   ...           0.0         0.0   \n",
      "4    0.234917    0.253137 -0.579693 -0.612646   ...           0.0         0.0   \n",
      "\n",
      "   Education5  Marital_Status0  Marital_Status1  Marital_Status2  card_class0  \\\n",
      "0         0.0              0.0              1.0              0.0          1.0   \n",
      "1         0.0              0.0              0.0              1.0          0.0   \n",
      "2         0.0              0.0              0.0              1.0          0.0   \n",
      "3         0.0              0.0              1.0              0.0          1.0   \n",
      "4         0.0              0.0              1.0              0.0          1.0   \n",
      "\n",
      "   card_class1  Default  Gender  \n",
      "0          0.0      1.0     2.0  \n",
      "1          1.0      0.0     2.0  \n",
      "2          1.0      0.0     2.0  \n",
      "3          0.0      0.0     2.0  \n",
      "4          0.0      0.0     1.0  \n",
      "\n",
      "[5 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "# The Imputed and Encoded Data\n",
    "data_array = np.hstack((scaled_interval_data, hot_array, imputed_binary_data))\n",
    "#col = (interval_attributes, cat_attributes)\n",
    "col = []\n",
    "for i in range(n_interval):\n",
    "    col.append(interval_attributes[i])\n",
    "for i in range(n_onehot):\n",
    "    col.append(onehot_attributes[i])\n",
    "for i in range(n_binary):\n",
    "    col.append(binary_attributes[i])\n",
    "df_imputed_scaled = pd.DataFrame(data_array,columns=col)\n",
    "df_imputed_scaled_lgr = df_imputed_scaled.drop(['Education6','Marital_Status3','card_class2'], axis = 1) \n",
    "print(\"\\nImputed & Scaled DataFrame:\\n\", df_imputed_scaled.head(),)\n",
    "print(\"\\nImputed & Scaled lgr DataFrame:\\n\", df_imputed_scaled_lgr.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Model using Entire Dataset\n",
      "\n",
      "Coefficients:\n",
      "Intercept......        -1.6860\n",
      "Age............         0.0646\n",
      "Credit_Limit...        -0.2967\n",
      "Jun_Status.....         0.7535\n",
      "May_Status.....         0.3222\n",
      "Apr_Status.....         0.1002\n",
      "Mar_Status.....         0.0978\n",
      "Feb_Status.....         0.1419\n",
      "Jan_Status.....         0.1726\n",
      "Jun_Bill.......        -0.2220\n",
      "May_Bill.......         0.3994\n",
      "Apr_Bill.......        -0.1362\n",
      "Mar_Bill.......         0.1415\n",
      "Feb_Bill.......        -0.0504\n",
      "Jan_Bill.......         0.0429\n",
      "Jun_Payment....        -0.2446\n",
      "May_Payment....        -0.1746\n",
      "Apr_Payment....        -0.0686\n",
      "Mar_Payment....        -0.0492\n",
      "Feb_Payment....        -0.1571\n",
      "Jan_Payment....        -0.0350\n",
      "Jun_PayPercent.         0.2483\n",
      "May_PayPercent.         0.1631\n",
      "Apr_PayPercent.        -0.0018\n",
      "Mar_PayPercent.         0.1200\n",
      "Feb_PayPercent.         0.1878\n",
      "Jan_PayPercent.         0.0613\n",
      "Education0.....        -0.5484\n",
      "Education1.....         0.2830\n",
      "Education2.....         0.2176\n",
      "Education3.....         0.1845\n",
      "Education4.....        -0.6777\n",
      "Education5.....        -0.8414\n",
      "Education6.....        -1.6177\n",
      "Marital_Status0        -0.0497\n",
      "Marital_Status1        -0.2392\n",
      "Marital_Status2        -0.2713\n",
      "Marital_Status3        -0.3653\n",
      "card_class0....        -0.0944\n",
      "\n",
      "Model Metrics\n",
      "Observations...............     30000\n",
      "Coefficients...............        39\n",
      "DF Error...................     29961\n",
      "Mean Absolute Error........    0.2100\n",
      "Avg Squared Error..........    0.1036\n",
      "Accuracy...................    0.8622\n",
      "Precision..................    0.6761\n",
      "Recall (Sensitivity).......    0.2851\n",
      "F1-Score...................    0.4011\n",
      "MISC (Misclassification)...     13.8%\n",
      "     class 0...............      2.6%\n",
      "     class 1...............     71.5%\n",
      "\n",
      "\n",
      "     Confusion\n",
      "       Matrix     Class 0   Class 1  \n",
      "Class 0.....     24483       663\n",
      "Class 1.....      3470      1384\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Class_regression import logreg\n",
    "y = np.asarray(df_imputed_scaled_lgr['Default']) \n",
    "X = np.asarray(df_imputed_scaled_lgr.drop('Default',axis=1))\n",
    "lgr = LogisticRegression()\n",
    "lgr.fit(X, y)\n",
    "print(\"\\nLogistic Regression Model using Entire Dataset\")\n",
    "logreg.display_coef(lgr, 38, 2, col)\n",
    "logreg.display_binary_metrics(lgr, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Network:  3\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8713    0.0069\n",
      "recall....... 0.4073    0.0459\n",
      "precision.... 0.6708    0.0434\n",
      "f1........... 0.5048    0.0352\n",
      "\n",
      "Network:  4\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8727    0.0087\n",
      "recall....... 0.4415    0.0399\n",
      "precision.... 0.6616    0.0480\n",
      "f1........... 0.5284    0.0345\n",
      "\n",
      "Network:  5\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8736    0.0074\n",
      "recall....... 0.4463    0.0343\n",
      "precision.... 0.6641    0.0409\n",
      "f1........... 0.5329    0.0293\n",
      "\n",
      "Network:  6\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8714    0.0075\n",
      "recall....... 0.4275    0.0274\n",
      "precision.... 0.6601    0.0438\n",
      "f1........... 0.5181    0.0256\n",
      "\n",
      "Network:  7\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8719    0.0076\n",
      "recall....... 0.4347    0.0339\n",
      "precision.... 0.6598    0.0452\n",
      "f1........... 0.5230    0.0297\n",
      "\n",
      "Network:  8\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8724    0.0077\n",
      "recall....... 0.4407    0.0398\n",
      "precision.... 0.6604    0.0443\n",
      "f1........... 0.5272    0.0317\n",
      "\n",
      "Network:  9\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8702    0.0085\n",
      "recall....... 0.4343    0.0344\n",
      "precision.... 0.6499    0.0482\n",
      "f1........... 0.5195    0.0315\n",
      "\n",
      "Network:  11\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8694    0.0073\n",
      "recall....... 0.4417    0.0358\n",
      "precision.... 0.6415    0.0389\n",
      "f1........... 0.5221    0.0288\n",
      "\n",
      "Network:  (3, 2)\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8730    0.0074\n",
      "recall....... 0.4541    0.0375\n",
      "precision.... 0.6573    0.0417\n",
      "f1........... 0.5359    0.0297\n",
      "\n",
      "Network:  (4, 3)\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8743    0.0072\n",
      "recall....... 0.4384    0.0396\n",
      "precision.... 0.6724    0.0421\n",
      "f1........... 0.5295    0.0323\n",
      "\n",
      "Network:  (5, 4)\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8720    0.0075\n",
      "recall....... 0.4502    0.0366\n",
      "precision.... 0.6536    0.0426\n",
      "f1........... 0.5318    0.0283\n",
      "\n",
      "Network:  (6, 5)\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8712    0.0065\n",
      "recall....... 0.4429    0.0386\n",
      "precision.... 0.6517    0.0364\n",
      "f1........... 0.5261    0.0291\n",
      "\n",
      "Network:  (7, 6)\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8711    0.0075\n",
      "recall....... 0.4520    0.0290\n",
      "precision.... 0.6465    0.0383\n",
      "f1........... 0.5315    0.0274\n",
      "\n",
      "Network:  (8, 7)\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8682    0.0071\n",
      "recall....... 0.4413    0.0412\n",
      "precision.... 0.6361    0.0431\n",
      "f1........... 0.5194    0.0294\n",
      "\n",
      "Network:  (9, 8)\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8668    0.0092\n",
      "recall....... 0.4411    0.0264\n",
      "precision.... 0.6270    0.0450\n",
      "f1........... 0.5174    0.0294\n",
      "\n",
      "Network:  (10, 10)\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8654    0.0080\n",
      "recall....... 0.4343    0.0433\n",
      "precision.... 0.6214    0.0401\n",
      "f1........... 0.5099    0.0344\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network  import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = np.asarray(df_imputed_scaled['Default']) \n",
    "X = np.asarray(df_imputed_scaled.drop('Default',axis=1))\n",
    "np_y = np.ravel(y)\n",
    "network_list = [(3),(4),(5),(6),(7),(8),(9), (11),(3,2),(4,3),(5,4), (6,5), (7,6),(8,7),(9,8),(10,10)]\n",
    "score_list = ['accuracy', 'recall', 'precision', 'f1']\n",
    "for nn in network_list:\n",
    "    print(\"\\nNetwork: \", nn)\n",
    "    fnn = MLPClassifier(hidden_layer_sizes=nn, activation='logistic', \\\n",
    "                    solver='lbfgs', max_iter=1000, random_state=12345)\n",
    "    fnn = fnn.fit(X,np_y)\n",
    "    scores = cross_validate(fnn, X, np_y, scoring=score_list, \\\n",
    "                            return_train_score=False, cv=10)\n",
    "    \n",
    "    print(\"{:.<13s}{:>6s}{:>13s}\".format(\"Metric\", \"Mean\", \"Std. Dev.\"))\n",
    "    for s in score_list:\n",
    "        var = \"test_\"+s\n",
    "        mean = scores[var].mean()\n",
    "        std  = scores[var].std()\n",
    "        print(\"{:.<13s}{:>7.4f}{:>10.4f}\".format(s, mean, std))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******** Decision Tree ********\n",
      "\n",
      "Maximum Tree Depth:  3\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8750    0.0068\n",
      "recall....... 0.4156    0.0309\n",
      "precision.... 0.6894    0.0402\n",
      "f1........... 0.5178    0.0291\n",
      "\n",
      "Maximum Tree Depth:  4\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8748    0.0077\n",
      "recall....... 0.4565    0.0333\n",
      "precision.... 0.6664    0.0408\n",
      "f1........... 0.5410    0.0299\n",
      "\n",
      "Maximum Tree Depth:  5\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8741    0.0071\n",
      "recall....... 0.4479    0.0403\n",
      "precision.... 0.6679    0.0449\n",
      "f1........... 0.5345    0.0302\n",
      "\n",
      "Maximum Tree Depth:  6\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8751    0.0066\n",
      "recall....... 0.4510    0.0384\n",
      "precision.... 0.6711    0.0363\n",
      "f1........... 0.5382    0.0301\n",
      "\n",
      "Maximum Tree Depth:  7\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8737    0.0069\n",
      "recall....... 0.4438    0.0341\n",
      "precision.... 0.6663    0.0392\n",
      "f1........... 0.5315    0.0275\n",
      "\n",
      "Maximum Tree Depth:  8\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8720    0.0070\n",
      "recall....... 0.4423    0.0398\n",
      "precision.... 0.6562    0.0382\n",
      "f1........... 0.5272    0.0311\n",
      "\n",
      "Maximum Tree Depth:  10\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8699    0.0082\n",
      "recall....... 0.4434    0.0316\n",
      "precision.... 0.6449    0.0471\n",
      "f1........... 0.5243    0.0275\n",
      "\n",
      "Maximum Tree Depth:  15\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8549    0.0086\n",
      "recall....... 0.4452    0.0295\n",
      "precision.... 0.5675    0.0377\n",
      "f1........... 0.4981    0.0254\n",
      "\n",
      "Maximum Tree Depth:  25\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8409    0.0100\n",
      "recall....... 0.4582    0.0259\n",
      "precision.... 0.5110    0.0363\n",
      "f1........... 0.4826    0.0251\n",
      "\n",
      "Maximum Tree Depth:  30\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8407    0.0105\n",
      "recall....... 0.4582    0.0245\n",
      "precision.... 0.5102    0.0376\n",
      "f1........... 0.4823    0.0259\n",
      "\n",
      "Maximum Tree Depth:  35\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8409    0.0108\n",
      "recall....... 0.4532    0.0214\n",
      "precision.... 0.5112    0.0393\n",
      "f1........... 0.4800    0.0261\n"
     ]
    }
   ],
   "source": [
    "from Class_tree import DecisionTree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from pydotplus import graph_from_dot_data\n",
    "import graphviz\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "y = df_imputed_scaled['Default']\n",
    "X = df_imputed_scaled.drop('Default',axis=1)\n",
    "print(\"\\n******** Decision Tree ********\")\n",
    "\n",
    "features = np.array(X.columns.values)\n",
    "classes = ['1','0']\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = \\\n",
    "            train_test_split(X,y,test_size = 0.3, random_state=12345)\n",
    "\n",
    "# Cross Validation\n",
    "depth_list = [3, 4, 5, 6, 7, 8, 10, 15, 25, 30, 35]\n",
    "score_list = ['accuracy', 'recall', 'precision', 'f1']\n",
    "\n",
    "for d in depth_list:\n",
    "    print(\"\\nMaximum Tree Depth: \", d)\n",
    "    dtc = DecisionTreeClassifier(max_depth=d, min_samples_leaf=5, min_samples_split=5)\n",
    "    dtc = dtc.fit(X,y)\n",
    "    scores = cross_validate(dtc, X, y, scoring=score_list, \\\n",
    "                            return_train_score=False, cv=10)\n",
    "    print(\"{:.<13s}{:>6s}{:>13s}\".format(\"Metric\", \"Mean\", \"Std. Dev.\"))\n",
    "    for s in score_list:\n",
    "        var = \"test_\" + s\n",
    "        mean = scores[var].mean()\n",
    "        std = scores[var].std()\n",
    "        print(\"{:.<13s}{:>7.4f}{:>10.4f}\".format(s, mean, std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******** RANDOM FOREST ********\n",
      "\n",
      "Number of Trees:  27  Max_features:  0.3\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8805    0.0060\n",
      "recall....... 0.4656    0.0336\n",
      "precision.... 0.6977    0.0369\n",
      "f1........... 0.5573    0.0242\n",
      "\n",
      "Number of Trees:  27  Max_features:  0.5\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8803    0.0051\n",
      "recall....... 0.4658    0.0333\n",
      "precision.... 0.6948    0.0297\n",
      "f1........... 0.5568    0.0243\n",
      "\n",
      "Number of Trees:  27  Max_features:  0.8\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8807    0.0059\n",
      "recall....... 0.4736    0.0368\n",
      "precision.... 0.6935    0.0321\n",
      "f1........... 0.5618    0.0271\n",
      "\n",
      "Number of Trees:  35  Max_features:  0.3\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8813    0.0065\n",
      "recall....... 0.4652    0.0330\n",
      "precision.... 0.7026    0.0394\n",
      "f1........... 0.5587    0.0262\n",
      "\n",
      "Number of Trees:  35  Max_features:  0.5\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8816    0.0054\n",
      "recall....... 0.4714    0.0347\n",
      "precision.... 0.7003    0.0309\n",
      "f1........... 0.5625    0.0251\n",
      "\n",
      "Number of Trees:  35  Max_features:  0.8\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8817    0.0051\n",
      "recall....... 0.4806    0.0382\n",
      "precision.... 0.6958    0.0282\n",
      "f1........... 0.5674    0.0254\n",
      "\n",
      "Number of Trees:  45  Max_features:  0.3\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8818    0.0068\n",
      "recall....... 0.4662    0.0336\n",
      "precision.... 0.7055    0.0403\n",
      "f1........... 0.5604    0.0272\n",
      "\n",
      "Number of Trees:  45  Max_features:  0.5\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8822    0.0052\n",
      "recall....... 0.4724    0.0369\n",
      "precision.... 0.7031    0.0272\n",
      "f1........... 0.5641    0.0268\n",
      "\n",
      "Number of Trees:  45  Max_features:  0.8\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8818    0.0063\n",
      "recall....... 0.4788    0.0381\n",
      "precision.... 0.6973    0.0334\n",
      "f1........... 0.5666    0.0283\n",
      "\n",
      "Number of Trees:  55  Max_features:  0.3\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8820    0.0065\n",
      "recall....... 0.4664    0.0318\n",
      "precision.... 0.7063    0.0399\n",
      "f1........... 0.5608    0.0256\n",
      "\n",
      "Number of Trees:  55  Max_features:  0.5\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8823    0.0055\n",
      "recall....... 0.4712    0.0332\n",
      "precision.... 0.7049    0.0307\n",
      "f1........... 0.5639    0.0254\n",
      "\n",
      "Number of Trees:  55  Max_features:  0.8\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8830    0.0062\n",
      "recall....... 0.4811    0.0380\n",
      "precision.... 0.7032    0.0328\n",
      "f1........... 0.5702    0.0282\n",
      "\n",
      "Number of Trees:  60  Max_features:  0.3\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8819    0.0064\n",
      "recall....... 0.4605    0.0332\n",
      "precision.... 0.7095    0.0385\n",
      "f1........... 0.5575    0.0269\n",
      "\n",
      "Number of Trees:  60  Max_features:  0.5\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8825    0.0054\n",
      "recall....... 0.4677    0.0338\n",
      "precision.... 0.7084    0.0308\n",
      "f1........... 0.5625    0.0254\n",
      "\n",
      "Number of Trees:  60  Max_features:  0.8\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8836    0.0059\n",
      "recall....... 0.4751    0.0400\n",
      "precision.... 0.7111    0.0332\n",
      "f1........... 0.5684    0.0288\n",
      "\n",
      "Number of Trees:  65  Max_features:  0.3\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8817    0.0065\n",
      "recall....... 0.4687    0.0335\n",
      "precision.... 0.7030    0.0389\n",
      "f1........... 0.5614    0.0265\n",
      "\n",
      "Number of Trees:  65  Max_features:  0.5\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8825    0.0056\n",
      "recall....... 0.4755    0.0356\n",
      "precision.... 0.7035    0.0310\n",
      "f1........... 0.5664    0.0261\n",
      "\n",
      "Number of Trees:  65  Max_features:  0.8\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8832    0.0059\n",
      "recall....... 0.4823    0.0397\n",
      "precision.... 0.7043    0.0332\n",
      "f1........... 0.5713    0.0276\n",
      "\n",
      "Number of Trees:  70  Max_features:  0.3\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8816    0.0058\n",
      "recall....... 0.4605    0.0330\n",
      "precision.... 0.7077    0.0362\n",
      "f1........... 0.5568    0.0247\n",
      "\n",
      "Number of Trees:  70  Max_features:  0.5\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8830    0.0056\n",
      "recall....... 0.4691    0.0375\n",
      "precision.... 0.7107    0.0324\n",
      "f1........... 0.5640    0.0272\n",
      "\n",
      "Number of Trees:  70  Max_features:  0.8\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8837    0.0057\n",
      "recall....... 0.4769    0.0382\n",
      "precision.... 0.7107    0.0338\n",
      "f1........... 0.5695    0.0265\n",
      "\n",
      "Number of Trees:  75  Max_features:  0.3\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8818    0.0063\n",
      "recall....... 0.4675    0.0332\n",
      "precision.... 0.7042    0.0369\n",
      "f1........... 0.5610    0.0261\n",
      "\n",
      "Number of Trees:  75  Max_features:  0.5\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8830    0.0055\n",
      "recall....... 0.4759    0.0360\n",
      "precision.... 0.7068    0.0337\n",
      "f1........... 0.5676    0.0252\n",
      "\n",
      "Number of Trees:  75  Max_features:  0.8\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8839    0.0061\n",
      "recall....... 0.4831    0.0390\n",
      "precision.... 0.7084    0.0358\n",
      "f1........... 0.5731    0.0273\n",
      "\n",
      "Number of Trees:  80  Max_features:  0.3\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8820    0.0063\n",
      "recall....... 0.4629    0.0340\n",
      "precision.... 0.7091    0.0400\n",
      "f1........... 0.5590    0.0260\n",
      "\n",
      "Number of Trees:  80  Max_features:  0.5\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8828    0.0060\n",
      "recall....... 0.4712    0.0376\n",
      "precision.... 0.7086    0.0350\n",
      "f1........... 0.5648    0.0278\n",
      "\n",
      "Number of Trees:  80  Max_features:  0.8\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8838    0.0066\n",
      "recall....... 0.4771    0.0396\n",
      "precision.... 0.7116    0.0370\n",
      "f1........... 0.5700    0.0295\n",
      "\n",
      "Best based on F1-Score\n",
      "Best Number of Estimators (trees) =  75\n",
      "Best Maximum Features =  0.8\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n******** RANDOM FOREST ********\")\n",
    "\n",
    "estimators_list = [27, 35, 45, 55, 60, 65, 70, 75, 80]\n",
    "max_features_list = [0.3, 0.5, 0.8]\n",
    "score_list = ['accuracy', 'recall', 'precision', 'f1']\n",
    "max_f1 = 0\n",
    "for e in estimators_list:\n",
    "    for f in max_features_list:\n",
    "        print(\"\\nNumber of Trees: \", e, \" Max_features: \", f)\n",
    "        rfc = RandomForestClassifier(n_estimators=e, criterion=\"gini\", \\\n",
    "                                     max_depth = None, min_samples_split=2, \\\n",
    "                                     min_samples_leaf=1, max_features=f, \\\n",
    "                                     n_jobs=4, bootstrap=True, random_state=12345)\n",
    "        rfc = rfc.fit(X, y)\n",
    "        scores = cross_validate(rfc, X, y, scoring=score_list, \\\n",
    "                                return_train_score=False, cv=10)\n",
    "\n",
    "        print(\"{:.<13s}{:>6s}{:>13s}\".format(\"Metric\", \"Mean\", \"Std. Dev.\"))\n",
    "        for s in score_list:\n",
    "            var = \"test_\" + s\n",
    "            mean = scores[var].mean()\n",
    "            std = scores[var].std()\n",
    "            print(\"{:.<13s}{:>7.4f}{:>10.4f}\".format(s, mean, std))\n",
    "        if mean > max_f1:\n",
    "            max_f1 = mean\n",
    "            best_estimator = e\n",
    "            best_max_features = f\n",
    "\n",
    "print(\"\\nBest based on F1-Score\")\n",
    "print(\"Best Number of Estimators (trees) = \", best_estimator)\n",
    "print(\"Best Maximum Features = \", best_max_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Data\n",
      "Random Selection of 70% of Original Data\n",
      "\n",
      "\n",
      "Model Metrics..........       Training     Validation\n",
      "Observations...........          21000           9000\n",
      "Coefficients...........             39             39\n",
      "DF Error...............          20961           8961\n",
      "Mean Absolute Error....         0.2086         0.2105\n",
      "Avg Squared Error......         0.1029         0.1045\n",
      "Accuracy...............         0.8639         0.8632\n",
      "Precision..............         0.6850         0.6463\n",
      "Recall (Sensitivity)...         0.3087         0.2980\n",
      "F1-score...............         0.4256         0.4079\n",
      "MISC (Misclassification)...      13.6%          13.7%\n",
      "     class 0...............       2.8%           3.1%\n",
      "     class 1...............      69.1%          70.2%\n",
      "\n",
      "\n",
      "Training\n",
      "Confusion Matrix  Class 0   Class 1  \n",
      "Class 0.....     17082       487\n",
      "Class 1.....      2372      1059\n",
      "\n",
      "\n",
      "Validation\n",
      "Confusion Matrix  Class 0   Class 1  \n",
      "Class 0.....      7345       232\n",
      "Class 1.....       999       424\n",
      "\n",
      "******** NEURAL NETWORK ********\n",
      "\n",
      "Model Metrics\n",
      "Observations...........          21000\n",
      "Features...............             38\n",
      "Number of Layers.......              2\n",
      "Number of Outputs......              1\n",
      "Number of Weights......            128\n",
      "Activation Function....       logistic\n",
      "Loss...................         0.0477\n",
      "R-Squared..............         0.3023\n",
      "Mean Absolute Error....         0.1906\n",
      "Median Absolute Error..         0.0763\n",
      "Avg Squared Error......         0.0954\n",
      "Square Root ASE........         0.3088\n",
      "\n",
      "Training Data\n",
      "Random Selection of 70% of Original Data\n",
      "\n",
      "\n",
      "Model Metrics..........       Training     Validation\n",
      "Observations...........          21000           9000\n",
      "Features...............             38             38\n",
      "Maximum Tree Depth.....              4              4\n",
      "Minimum Leaf Size......              5              5\n",
      "Minimum split Size.....              5              5\n",
      "Mean Absolute Error....         0.1933         0.1952\n",
      "Avg Squared Error......         0.0967         0.0986\n",
      "Accuracy...............         0.8760         0.8726\n",
      "Precision..............         0.6673         0.6322\n",
      "Recall (Sensitivity)...         0.4800         0.4638\n",
      "F1-score...............         0.5584         0.5351\n",
      "MISC (Misclassification)...      12.4%          12.7%\n",
      "     class 0...............       4.7%           5.1%\n",
      "     class 1...............      52.0%          53.6%\n",
      "\n",
      "\n",
      "Training\n",
      "Confusion Matrix  Class 0   Class 1  \n",
      "Class 0.....     16748       821\n",
      "Class 1.....      1784      1647\n",
      "\n",
      "\n",
      "Validation\n",
      "Confusion Matrix  Class 0   Class 1  \n",
      "Class 0.....      7193       384\n",
      "Class 1.....       763       660\n",
      "\n",
      " Random forest: Training Data\n",
      "Random Selection of 70% of Original Data\n",
      "\n",
      "\n",
      "Model Metrics..........       Training     Validation\n",
      "Observations...........          21000           9000\n",
      "Features...............             38             38\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to NoneType.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-d78a1c06fd8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n Random forest: Training Data\\nRandom Selection of 70% of Original Data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mDecisionTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay_binary_split_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfc_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_validate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_validate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfc_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:/yoyo/course/3rd/656/hom/week5\\Class_tree.py\u001b[0m in \u001b[0;36mdisplay_binary_split_metrics\u001b[1;34m(dt, Xt, yt, Xv, yv)\u001b[0m\n\u001b[0;32m    153\u001b[0m                                                           Xv.shape[1]))\n\u001b[0;32m    154\u001b[0m         print(\"{:.<23s}{:15d}{:15d}\".format('Maximum Tree Depth',\\\n\u001b[1;32m--> 155\u001b[1;33m                               dt.max_depth, dt.max_depth))\n\u001b[0m\u001b[0;32m    156\u001b[0m         print(\"{:.<23s}{:15d}{:15d}\".format('Minimum Leaf Size', \\\n\u001b[0;32m    157\u001b[0m                               dt.min_samples_leaf, dt.min_samples_leaf))\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported format string passed to NoneType.__format__"
     ]
    }
   ],
   "source": [
    "X_train, X_validate, y_train, y_validate = \\\n",
    "            train_test_split(X,y,test_size = 0.3, random_state=7)\n",
    "#logistic\n",
    "lgr_train = LogisticRegression()\n",
    "lgr_train.fit(X_train, y_train)\n",
    "print(\"\\nTraining Data\\nRandom Selection of 70% of Original Data\")\n",
    "logreg.display_binary_split_metrics(lgr_train, X_train, y_train, \\\n",
    "                                     X_validate, y_validate)\n",
    "#nerual\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from Class_FNN import NeuralNetwork\n",
    "np_y_train = np.ravel(y_train)\n",
    "print(\"\\n******** NEURAL NETWORK ********\")\n",
    "#Neural Network\n",
    "fnn = MLPRegressor(hidden_layer_sizes=(3,2), activation='logistic', \\\n",
    "                    solver='lbfgs', max_iter=1000, random_state=12345)\n",
    "fnn = fnn.fit(X_train, np_y_train)\n",
    "#NeuralNetwork.display_nominal_metrics(fnn, X, y)\n",
    "NeuralNetwork.display_metrics(fnn, X_train, y_train)\n",
    "\n",
    "#dt\n",
    "from Class_tree import DecisionTree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(max_depth=4, min_samples_leaf=5, min_samples_split=5)\n",
    "dtc_test = dtc.fit(X_train,y_train)\n",
    "\n",
    "y_pred = dtc_test.predict(X_validate)\n",
    "\n",
    "print(\"\\nTraining Data\\nRandom Selection of 70% of Original Data\")\n",
    "\n",
    "DecisionTree.display_binary_split_metrics(dtc_test, X_train, y_train, X_validate, y_validate)\n",
    "\n",
    "#rf\n",
    "rfc = RandomForestClassifier(n_estimators=best_estimator, criterion=\"gini\", \\\n",
    "                    max_depth=None, min_samples_split=2, \\\n",
    "                    min_samples_leaf=1, max_features= best_max_features, \\\n",
    "                    n_jobs=1, bootstrap=True, random_state=12345)\n",
    "\n",
    "rfc_test = rfc.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n Random forest: Training Data\\nRandom Selection of 70% of Original Data\")\n",
    "\n",
    "DecisionTree.display_binary_split_metrics(rfc_test, X_train, y_train, X_validate, y_validate)\n",
    "DecisionTree.display_importance(rfc_test, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
